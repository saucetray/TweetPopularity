README "search.py" - 


This script requires a valid Twitter API account:
 	1. with a valid Bearer Token inserted as the string variable 'bt' on line 16 of 'search.py'.
	2. with valid API keys and secrets specified in '.twitter_keys.yaml'.

The script uses a modified version of Twitter's public API python scripts that were designed to allow automation of API calls for developers.


Script flow:
	getRecentTweets():
		This function performs an API search of the most recent tweets posted on twitter.
		It gathers them in batches of 100 tweets and is used to generate random users to sample timeline data from.

		**Input file(s): None.

		**Outputs: 'testJson.json' containing the sampled twitter data.

	filter_for_en():
		This function processes the tweets found through the recent search and removes tweets that have a language attribute not equal to 'en'.
		Removing most non-english tweets from our data set.
		*some tweets are improperly labeled as 'en' which can allow non-english tweets to enter our data set

		**Input file(s): 'testJson.json'

		**Outputs: 'enUsers.json' containing english-filtered sampled twitter data.

	genIdList():
		This function iterates through the now english filtered tweets and extracts the author's twitter user ID number.
		

		**Input file(s): 'enUsers.json'

		**Outputs: 'userlist.txt' a text file with all of the individual author's User ID from 'enUsers.json' split by carriage returns ('\n'). 
	

	getLatestTweetsUser():
		This function iterates through the list of User IDs in 'userlist.txt' and accesses their twitter timeline through a headless web
		browser.
		
		The resulting HTML is processed using beautifulsoup to extract the tweets contained in the HTML code and stores their unique Tweet IDs.

		**Input file(s): 'userlist.txt'
		**Outputs: 'idLists.json' a json file containing a list of twitter users and their list of Tweet IDs extracted from their timeline.

	genUserList():
		This function combines the data of 'enUsers.json' and 'idLists.json' into one json file containing user objects and their list of recent tweets.

		**Input file(s): 'enUsers.json', 'idLists.json'
		**Outputs: 'enUsers_Tweets.json' a json file containing twitter user objects and their list of recent tweets extracted from their timeline.

	usersTweetsByIds():
		This function iterates through the sampled users and accesses the Twitter API endpoint to get the tweet objects for each of their Tweet IDs.
		The API returns the tweet's text contents, and public_metrics (likes, retweets, etc.).
		The list of tweet objects is attached to their associated user object.

		**Input file(s): 'enUsers_Tweets.json'
		**Outputs: 'Random_WithTweets.json' a json file containing twitter user objects and their list of recent tweet objects.

	split_users():
		This function performs extra processing on the tweet objects that were collected in 'userTweetsByIds'.
		It checks to make sure retweets are filtered out, by verifying the author_id of the user object and author_id of the tweet object are equal.
		It also restructures the json file to only contain user objects and removing the redundant tweet objects that were previously generated by 'getRecentTweets'.

		**Input file(s): 'Random_WithTweets.json'
		**Outputs: 'Random_WithTweets.json' a json file containing only twitter user objects and their list of recent tweet objects, with redundancies removed.		

These functions will loop as many times as specified on line 283.
	Each loop will produce 0-100 user objects and append to the 'RandomUsers_WithTweets.json'
	The more iterations, the more user objects and their tweet objects that will be collected.