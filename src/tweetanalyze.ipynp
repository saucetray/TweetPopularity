{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERTClassification",
      "provenance": [],
      "collapsed_sections": [
        "qYzEHqqlgx1S"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0705999e045845be9854e917dd0ab92e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3c56d9ff1a714d3ba0864844478cda7d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cdb6cf3e428e441c8fa6d4f0e1c90fe0",
              "IPY_MODEL_6eff1a3259754340bfe94e156f5e64fb"
            ]
          }
        },
        "3c56d9ff1a714d3ba0864844478cda7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cdb6cf3e428e441c8fa6d4f0e1c90fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1ae48c3800524b2b8f23445468a7020e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1e34bd77078a490980846b95b6dcd188"
          }
        },
        "6eff1a3259754340bfe94e156f5e64fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e1de4056e27e4041b8b3c6112378128a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [01:44&lt;00:00, 4.14B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a3e4bb383db44018a6f23b88f969f17"
          }
        },
        "1ae48c3800524b2b8f23445468a7020e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1e34bd77078a490980846b95b6dcd188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1de4056e27e4041b8b3c6112378128a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a3e4bb383db44018a6f23b88f969f17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4013e33d385a471382a8670aedc7ce5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_210c58c81fa444d9b5a3b5fe965de1dd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_318e4184939c426290a574bf7388feac",
              "IPY_MODEL_d6a7ba8f56034188b9721d311ff2d9d2"
            ]
          }
        },
        "210c58c81fa444d9b5a3b5fe965de1dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "318e4184939c426290a574bf7388feac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fc96819819a34cb0a1f9d216a97dff03",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_282557816b274a2da4bc921dfbc80026"
          }
        },
        "d6a7ba8f56034188b9721d311ff2d9d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_95fb34fa1ae74fb1b59c7d183a529d1f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:06&lt;00:00, 64.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5dfa654a409442b8b0fdb14a1d298723"
          }
        },
        "fc96819819a34cb0a1f9d216a97dff03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "282557816b274a2da4bc921dfbc80026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "95fb34fa1ae74fb1b59c7d183a529d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5dfa654a409442b8b0fdb14a1d298723": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYzEHqqlgx1S"
      },
      "source": [
        "# RUNNING\n",
        "Please use a GPU to increase the speed of this.\n",
        "If you don't... it will take longer but you can still use this at the expense of your time.\n",
        "\n",
        "## Where Tested\n",
        "\n",
        "This is tested on Google Colab and also works on your own computer with \n",
        "the correct libraries.\n",
        "\n",
        "# ACKOWLEDGEMENT\n",
        "**Moat of the code here is taken or inspired by https://mccormickml.com/2019/07/22/BERT-fine-tuning/#41-bertforsequenceclassification**\n",
        "\n",
        "**The Bert pre-trained model is from https://github.com/VinAIResearch/BERTweet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tyr1JS3oo4d7"
      },
      "source": [
        "# Importing and Installing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CkOaSmyo9Fb",
        "outputId": "61b856e9-2225-4b0d-d412-719b357506c4"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install emoji"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)\n",
            "\r\u001b[K     |▎                               | 10kB 22.0MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 16.4MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 14.8MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 14.4MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 11.9MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 12.0MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 11.8MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 12.0MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92kB 12.8MB/s eta 0:00:01\r\u001b[K     |██▍                             | 102kB 12.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 112kB 12.9MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 12.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 133kB 12.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 143kB 12.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 153kB 12.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 163kB 12.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 174kB 12.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 184kB 12.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 194kB 12.9MB/s eta 0:00:01\r\u001b[K     |████▉                           | 204kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 215kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 225kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 235kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 245kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 256kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 266kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 276kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 286kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 296kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 307kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 317kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 327kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 337kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 348kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 358kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 368kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 378kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 389kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 399kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 409kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 419kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 430kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 440kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 450kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 460kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 471kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 481kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 491kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 501kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 512kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 522kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 532kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 542kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 552kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 563kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 573kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 583kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 593kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 604kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 614kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 624kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 634kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 645kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 655kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 665kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 675kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 686kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 696kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 706kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 716kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 727kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 737kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 747kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 757kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 768kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 778kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 788kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 798kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 808kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 819kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 829kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 839kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 849kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 860kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 870kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 880kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 890kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 901kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 911kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 921kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 931kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 942kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 952kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 962kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 972kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 983kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 993kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.0MB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.0MB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.0MB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.0MB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1MB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.1MB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.1MB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1MB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.1MB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2MB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.2MB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.2MB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.2MB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.2MB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.2MB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.3MB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.3MB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.3MB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.3MB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 12.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 52.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 42.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=9187e4eb513a7a173268e586e316d643fad53057dba6d5e013208f0515e71eaf\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.0\n",
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/1c/1f1457fe52d0b30cbeebfd578483cedb3e3619108d2d5a21380dfecf8ffd/emoji-0.6.0.tar.gz (51kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.6.0-cp36-none-any.whl size=49716 sha256=7f2216fcd6e80360be10b488502768098853317a57e5c81383140e36ff7d27e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/2c/8b/9dcf5216ca68e14e0320e283692dce8ae321cdc01e73e17796\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuvfh5Kdx3iO"
      },
      "source": [
        "# imports\n",
        "\n",
        "import json\n",
        "import transformers\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer \n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import statistics\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import joblib\n",
        "\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, precision_score\n",
        "from sklearn.metrics import recall_score, classification_report\n",
        "from transformers import BertweetTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', normalization=True)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4n-nqsI9qWV3"
      },
      "source": [
        "# Loading Existing Model and Parameters\n",
        "\n",
        "## The Existing Model\n",
        "\n",
        "You can load the existing model here that was created and stored in model_save. This model can then be used to train again or to classify tweets\n",
        "\n",
        "## The Parameters\n",
        "\n",
        "The parameters (the data loaders) are stored and loaded as well so that training can happen the same exact way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMPoraPx55oV",
        "outputId": "cb8e554e-6a76-48cf-c475-dcb2b7c76aee"
      },
      "source": [
        "!unzip ./model_save.zip"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./model_save.zip\n",
            "   creating: model_save/\n",
            "  inflating: model_save/pytorch_model.bin  \n",
            "  inflating: model_save/tokenizer_config.json  \n",
            "  inflating: model_save/config.json  \n",
            "  inflating: model_save/vocab.txt    \n",
            "   creating: model_save/params/\n",
            "  inflating: model_save/params/training_data_loader  \n",
            "  inflating: model_save/params/validation_data_loader  \n",
            "  inflating: model_save/special_tokens_map.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9DD7aCeqV8J",
        "outputId": "c809aede-18a0-4411-b039-856fa9d768a2"
      },
      "source": [
        "save_dir = './model_save/'\n",
        "save_dir_params = './model_save/params/'\n",
        "model = BertForSequenceClassification.from_pretrained(save_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', normalization=True)\n",
        "\n",
        "with open(save_dir_params + 'training_data_loader', 'rb') as f:\n",
        "  train_dataloader = joblib.load(f)  # loading data used in training\n",
        "with open(save_dir_params + 'validation_data_loader', 'rb') as f:\n",
        "  validation_dataloader = joblib.load(f)  # loading data used in training\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(get_gpu())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zTgRJVsrP3N"
      },
      "source": [
        "# GPU and Required Code Throughout\n",
        "It is encouraged to run this with a GPU\n",
        "\n",
        "If using google colab, go to runtime -> change runtime type -> GPU\n",
        "\n",
        "Also run all of these cells as they are needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjfeUJAEvtk0"
      },
      "source": [
        "# If there's a GPU available or returns the cpu...\n",
        "\n",
        "def exists_gpu():\n",
        "  if torch.cuda.is_available():\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def get_gpu():\n",
        "  if exists_gpu():\n",
        "      return torch.device(\"cuda\")\n",
        "      print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "  else:\n",
        "      print('No GPU available, using the CPU instead.')\n",
        "      return torch.device(\"cpu\")\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a-7ankV7aCo"
      },
      "source": [
        "# this block is for preprocessing tweets into a CSV\n",
        "\n",
        "# gets our tweet data from celebrities.\n",
        "# our celebrity json is different from our random tweets.\n",
        "# our celebrity json files are formatted differently.\n",
        "# You can find our formats in the accompanying .md files\n",
        "def get_tweets_into_csv_from_celebrities(csv_file, files):\n",
        "  count = 0\n",
        "  sentiments = []\n",
        "  if os.path.exists(csv_file):\n",
        "    os.remove(csv_file)\n",
        "  with open(csv_file, 'w+') as t:\n",
        "    # t.write('sentence_source,label,label_notes,sentence\\n')\n",
        "    for file in files:\n",
        "      if os.path.exists(file) and file.split('.')[-1] == 'json':\n",
        "        tweets = []\n",
        "        popular_indexes = []\n",
        "        try:\n",
        "          with open(file, 'r') as f:\n",
        "            tweets_data = json.load(f)\n",
        "          # followers and name are maybe useful\n",
        "          followers = tweets_data['user_info']['public_metrics']['followers_count']\n",
        "          name      = tweets_data['user_info']['name']\n",
        "          # this loops through every tweet we have and puts it into a format\n",
        "          # so that we can determine if it is popular and then write to a csv\n",
        "          for tweet in tweets_data['data']:\n",
        "            count += 1\n",
        "            sentiments.append(tweet['sentiment_score'])\n",
        "            retweets  = tweet['public_metrics']['retweet_count']\n",
        "            replies   = tweet['public_metrics']['reply_count']\n",
        "            quotes    = tweet['public_metrics']['quote_count']\n",
        "            likes     = tweet['public_metrics']['like_count']\n",
        "            tweet     = '\\\"' + tweet['text'].replace('\\n', '').replace(',','') + '\\\"'\n",
        "            popular   = popularity_index(likes, replies, quotes, retweets)\n",
        "            popular_indexes.append(popular)\n",
        "            tweets.append([name, followers, retweets, replies, quotes, \n",
        "                            likes, tweet, None])\n",
        "          stdev = statistics.pstdev(popular_indexes)\n",
        "          average = statistics.mean(popular_indexes)\n",
        "\n",
        "          for tweet, index in zip(tweets, popular_indexes):\n",
        "            normal = normalize(average, stdev, index)\n",
        "            if normal < .5:\n",
        "              tweet[7] = 0\n",
        "            else:\n",
        "              tweet[7] = 1\n",
        "            \n",
        "            # write to the file\n",
        "            t.write('%s,%i,%s,%s\\n' % (tweet[0], tweet[7], 'NaN', \n",
        "                                                    tweet[6]))\n",
        "        except:\n",
        "            print('File %s is corrupted' % file)\n",
        "\n",
        "  return count, sentiments\n",
        "\n",
        "# normalizes our tweets so 2/3 of data is between 0.25 and 0.75\n",
        "def normalize(average, stdev, index):\n",
        "  almost_normal = (index - average) / stdev\n",
        "  # remove any extrenuous data\n",
        "  if almost_normal < -2:\n",
        "    almost_normal = -2\n",
        "  elif almost_normal > 2:\n",
        "    almost_normal = 2\n",
        "  \n",
        "  return almost_normal / 5 + .5\n",
        "\n",
        "# we will use this to determine if a tweet is popular\n",
        "def popularity_index(likes, replies, quotes, retweets):\n",
        "  return likes\n",
        "  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILjlT-s9qNxh"
      },
      "source": [
        "# these are for accuracy purposes courtesy of \n",
        "# https://mccormickml.com/2019/07/22/BERT-fine-tuning/#41-bertforsequenceclassification\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeM0BEkserSe"
      },
      "source": [
        "# this will evaluate our baseline so we can compare it to our bert later to see if there is any improvement\n",
        "# we might try to even incorporate a word2vec instead of this baseline so it is a little better\n",
        "# since word2vec and bert both try to vectorize words\n",
        "\n",
        "def normalize_sentiment_values(sentiment_values):\n",
        "  print(len(sentiment_values))\n",
        "  for index in range(len(sentiment_values)):\n",
        "    value = sentiment_values[index]\n",
        "    if value < 0.5:\n",
        "      sentiment_values[index] = 0\n",
        "    elif value >= 0.5:\n",
        "      sentiment_values[index] = 1\n",
        "  return sentiment_values\n",
        "      \n",
        "def evaluate(y_true, sentiment_values):\n",
        "  y_pred = normalize_sentiment_values(sentiment_values)\n",
        "  print(len(y_pred))\n",
        "  print('confusion matrix :\\n', confusion_matrix(y_true,y_pred))\n",
        "  print('precision_score :\\n', precision_score(y_true,y_pred,pos_label=1))\n",
        "  print('recall_score :\\n', recall_score(y_true,y_pred,pos_label=1))\n",
        "  print('classification_report :\\n', classification_report(y_true,y_pred)) \n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDt_F845BXtb"
      },
      "source": [
        "def get_tweets_into_csv_from_random(csv_file, file):\n",
        "  count = 0\n",
        "  sentiments = []\n",
        "  if os.path.exists(csv_file):\n",
        "    os.remove(csv_file)\n",
        "  with open(csv_file, 'w+') as t:\n",
        "    if os.path.exists(file) and file.split('.')[-1] == 'json':\n",
        "      tweets = []\n",
        "      popular_indexes = []\n",
        "      with open(file, 'r') as f:\n",
        "        tweets_data = json.load(f)\n",
        "      for data in tweets_data['data']:\n",
        "        name      = data['name']\n",
        "        followers = data['public_metrics']['followers_count']\n",
        "        for tweet in data['tweets']:\n",
        "          count += 1\n",
        "          sentiments.append(tweet['sentiment_score'])\n",
        "          retweets  = tweet['public_metrics']['retweet_count']\n",
        "          replies   = tweet['public_metrics']['reply_count']\n",
        "          quotes    = tweet['public_metrics']['quote_count']\n",
        "          likes     = tweet['public_metrics']['like_count']\n",
        "          tweet     = '\\\"' + tweet['text'].replace('\\n', '').replace(',','') + '\\\"'\n",
        "          popular   = popularity_index(likes, replies, quotes, retweets)\n",
        "          popular_indexes.append(popular)\n",
        "          tweets.append([name, followers, retweets, replies, quotes, \n",
        "                          likes, tweet, None])\n",
        "        stdev = statistics.pstdev(popular_indexes)\n",
        "        average = statistics.mean(popular_indexes)\n",
        "\n",
        "        for tweet, index in zip(tweets, popular_indexes):\n",
        "          normal = normalize(average, stdev, index)\n",
        "          if normal < .5:\n",
        "            tweet[7] = 0\n",
        "          else:\n",
        "            tweet[7] = 1\n",
        "          \n",
        "          # write to the file\n",
        "          t.write('%s,%i,%s,%s\\n' % (tweet[0], tweet[7], 'NaN', \n",
        "                                                  tweet[6]))\n",
        "\n",
        "  return count, sentiments"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7ghR_5lo9kX"
      },
      "source": [
        "# Training Algorithms\n",
        "\n",
        "Training is done in the below scripts. \n",
        "It is important that you run the ones you want to run.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0_oJXuo7vYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20eb9cff-a492-463d-93e3-b08a1c1355ee"
      },
      "source": [
        "# preprocesssing of any set of .json data for tweets.... \n",
        "# this goes through all the json files in a director\n",
        "from os import walk\n",
        "\n",
        "tweet_directory = '.' # change if you want to change where the json files are \n",
        "                      # located. \n",
        "f = []\n",
        "for (dirpath, dirnames, filenames) in walk(tweet_directory):\n",
        "    f = filenames\n",
        "    break\n",
        "\n",
        "train_data_celebs = f[:int(len(f)//1.3)]\n",
        "\n",
        "csv_file_train_celeb = 'tweets_train_celeb.csv'\n",
        "\n",
        "count_train_celebs, sentiments_train_celebs = get_tweets_into_csv_from_celebrities(csv_file=csv_file_train_celeb, files=train_data_celebs)\n",
        "\n",
        "print('Amount of tweets in the training pool: %i' % count_train_celebs)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Amount of tweets in the training pool: 2693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pOzv4S27yBb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "edef6991-b818-44a7-960e-6b332f9968e0"
      },
      "source": [
        "# Load the dataset into a pandas dataframe.\n",
        "df_train_celeb = pd.read_csv(csv_file_train_celeb, delimiter=',', header=None, \n",
        "                             names=['sentence_source', 'label', \n",
        "                                    'label_notes', 'sentence'])\n",
        "\n",
        "print('Number of training sentences: %i \\n' % df_train_celeb.shape[0])\n",
        "# display random rows\n",
        "df_train_celeb.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 2693 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>Justin Bieber</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Well deserved @justinbieber! He's taking home ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2189</th>\n",
              "      <td>Avril Lavigne</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Love this 🙏🙏🙏 https://t.co/cnXQBcSCf8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>Dwayne Johnson</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just posted a photo https://t.co/NmHWn8HuqX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2501</th>\n",
              "      <td>Lil Wayne WEEZY F</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I live the way I love and love the way I live....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1837</th>\n",
              "      <td>Leonardo DiCaprio</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://t.co/XNxhIEg49E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>Marshall Mathers</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>In response to @revolttv... https://t.co/XrFJi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1685</th>\n",
              "      <td>ESPN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Luka Garza's 76 points over his last two games...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1146</th>\n",
              "      <td>Liam</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#NaughtyList featuring @dixiedamelio is OUT NO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Bernie Sanders</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Amazon Facebook Google and Apple made over $54...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958</th>\n",
              "      <td>Cole M. Sprouse</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>My ass the thickiest.  My toks the tickiest.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        sentence_source  ...                                           sentence\n",
              "459       Justin Bieber  ...  Well deserved @justinbieber! He's taking home ...\n",
              "2189      Avril Lavigne  ...              Love this 🙏🙏🙏 https://t.co/cnXQBcSCf8\n",
              "197      Dwayne Johnson  ...        Just posted a photo https://t.co/NmHWn8HuqX\n",
              "2501  Lil Wayne WEEZY F  ...  I live the way I love and love the way I live....\n",
              "1837  Leonardo DiCaprio  ...                            https://t.co/XNxhIEg49E\n",
              "291    Marshall Mathers  ...  In response to @revolttv... https://t.co/XrFJi...\n",
              "1685               ESPN  ...  Luka Garza's 76 points over his last two games...\n",
              "1146               Liam  ...  #NaughtyList featuring @dixiedamelio is OUT NO...\n",
              "31       Bernie Sanders  ...  Amazon Facebook Google and Apple made over $54...\n",
              "958     Cole M. Sprouse  ...       My ass the thickiest.  My toks the tickiest.\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dZUBwam70EY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "820d3d2b-f449-48fb-fba7-1b50720c6a49"
      },
      "source": [
        "# print some samples of our data to show that everything is good ...\n",
        "print('----------------------Popular-----------------------')\n",
        "print(df_train_celeb.loc[df_train_celeb.label == 1].sample(10)[['sentence', 'label']])\n",
        "print('---------------------Un-Popular---------------------')\n",
        "print(df_train_celeb.loc[df_train_celeb.label == 0].sample(10)[['sentence', 'label']])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------Popular-----------------------\n",
            "                                               sentence  label\n",
            "2069  Milan was so happy this morning to learn that ...      1\n",
            "2420  How about a little #90svibes to bring some fas...      1\n",
            "1122                                 Miss it every day!      1\n",
            "1414                                   Y’all catchin on      1\n",
            "2240  Education today tends to focus on material goa...      1\n",
            "1968  #PCAs @peopleschoice leggooooo ☄️💥🔥✨ (song: NT...      1\n",
            "909   Laugh now Cry later (Official Video) https://t...      1\n",
            "524   We hope to confirm a record tomorrow which wil...      1\n",
            "1377  Whatever women do they must do twice as well a...      1\n",
            "1816  Make sure you take care of yourself while the ...      1\n",
            "---------------------Un-Popular---------------------\n",
            "                                               sentence  label\n",
            "2315  Cheers 🥃 To Corporations Asking For More Ludac...      0\n",
            "1298  'I wasn't made for rain where's the sun!?' htt...      0\n",
            "317   Want to wear\" my Twitter quotes and other cosm...      0\n",
            "1004  Watch this month's best SoulCalibur VI players...      0\n",
            "2032                 #LockHimUp https://t.co/rKAW8smqFy      0\n",
            "1663  Happy Birthday 🎂🎁🎈 @agnezmo https://t.co/vMMwt...      0\n",
            "1525  “Jingle Jangle: A Christmas Journey” is coming...      0\n",
            "2110  Watch me play @ELLEmagazine's Song Association...      0\n",
            "1119  New merch alert! Drop 1 is now live on the mer...      0\n",
            "69    Aston Villa took the Carabao Cup!  Up the Vill...      0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4GiSSCXgiTM",
        "outputId": "7df3a947-c2e8-4e37-a346-59524b3ed76f"
      },
      "source": [
        "# to evaluate our baseline\n",
        "# we should use a baseline using word2vec probably\n",
        "\n",
        "labels = list(df_train_celeb.label.values)\n",
        "evaluate(labels, sentiments_train_celebs)\n",
        "matthews_corrcoef(labels, sentiments_train_celebs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2693\n",
            "2693\n",
            "confusion matrix :\n",
            " [[ 216 1740]\n",
            " [ 105  632]]\n",
            "precision_score :\n",
            " 0.26644182124789206\n",
            "recall_score :\n",
            " 0.8575305291723202\n",
            "classification_report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.11      0.19      1956\n",
            "           1       0.27      0.86      0.41       737\n",
            "\n",
            "    accuracy                           0.31      2693\n",
            "   macro avg       0.47      0.48      0.30      2693\n",
            "weighted avg       0.56      0.31      0.25      2693\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.04408604396716041"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwC2KC0J72La",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2e4e2c9-3876-4cad-c7eb-56586a84e163"
      },
      "source": [
        "sentences = df_train_celeb.sentence.values\n",
        "labels = df_train_celeb.label.values\n",
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Big banks are making record profits by charging sky-high interest rates &amp; fees. Unacceptable. If we're going to rebuild the middle class we must significantly reduce consumer debt. I will be reintroducing my bill to end Wall Street greed &amp; cap credit card interest rates at 15%.\n",
            "Tokenized:  ['big', 'banks', 'are', 'making', 'record', 'profits', 'by', 'charging', 'sky', '-', 'high', 'interest', 'rates', '&', 'amp', ';', 'fees', '.', 'unacceptable', '.', 'if', 'we', \"'\", 're', 'going', 'to', 'rebuild', 'the', 'middle', 'class', 'we', 'must', 'significantly', 'reduce', 'consumer', 'debt', '.', 'i', 'will', 'be', 'rein', '##tro', '##du', '##cing', 'my', 'bill', 'to', 'end', 'wall', 'street', 'greed', '&', 'amp', ';', 'cap', 'credit', 'card', 'interest', 'rates', 'at', '15', '%', '.']\n",
            "Token IDs:  [2502, 5085, 2024, 2437, 2501, 11372, 2011, 13003, 3712, 1011, 2152, 3037, 6165, 1004, 23713, 1025, 9883, 1012, 21873, 1012, 2065, 2057, 1005, 2128, 2183, 2000, 14591, 1996, 2690, 2465, 2057, 2442, 6022, 5547, 7325, 7016, 1012, 1045, 2097, 2022, 27788, 13181, 8566, 6129, 2026, 3021, 2000, 2203, 2813, 2395, 22040, 1004, 23713, 1025, 6178, 4923, 4003, 3037, 6165, 2012, 2321, 1003, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpuY7iDM738U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5cac465-1bd3-4c0f-f448-05a050ede0cf"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                    \n",
        "                        add_special_tokens = True, \n",
        "                        max_length = 130,          \n",
        "                        padding='max_length',\n",
        "                        return_attention_mask = True, \n",
        "                        return_tensors = 'pt', \n",
        "                   )\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Big banks are making record profits by charging sky-high interest rates &amp; fees. Unacceptable. If we're going to rebuild the middle class we must significantly reduce consumer debt. I will be reintroducing my bill to end Wall Street greed &amp; cap credit card interest rates at 15%.\n",
            "Token IDs: tensor([  101,  2502,  5085,  2024,  2437,  2501, 11372,  2011, 13003,  3712,\n",
            "         1011,  2152,  3037,  6165,  1004, 23713,  1025,  9883,  1012, 21873,\n",
            "         1012,  2065,  2057,  1005,  2128,  2183,  2000, 14591,  1996,  2690,\n",
            "         2465,  2057,  2442,  6022,  5547,  7325,  7016,  1012,  1045,  2097,\n",
            "         2022, 27788, 13181,  8566,  6129,  2026,  3021,  2000,  2203,  2813,\n",
            "         2395, 22040,  1004, 23713,  1025,  6178,  4923,  4003,  3037,  6165,\n",
            "         2012,  2321,  1003,  1012,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qw9EvEV75s-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad7b6751-9c45-4ee0-958b-0be049e000e5"
      },
      "source": [
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.90 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2,423 training samples\n",
            "  270 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyUl-Bb677-M"
      },
      "source": [
        "# we are making our batches now for training this will overwrite saved one\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# we have now training data at random \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  \n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "# our training data to train on :)\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset,\n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1KApJnL8Alw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "0705999e045845be9854e917dd0ab92e",
            "3c56d9ff1a714d3ba0864844478cda7d",
            "cdb6cf3e428e441c8fa6d4f0e1c90fe0",
            "6eff1a3259754340bfe94e156f5e64fb",
            "1ae48c3800524b2b8f23445468a7020e",
            "1e34bd77078a490980846b95b6dcd188",
            "e1de4056e27e4041b8b3c6112378128a",
            "2a3e4bb383db44018a6f23b88f969f17",
            "4013e33d385a471382a8670aedc7ce5d",
            "210c58c81fa444d9b5a3b5fe965de1dd",
            "318e4184939c426290a574bf7388feac",
            "d6a7ba8f56034188b9721d311ff2d9d2",
            "fc96819819a34cb0a1f9d216a97dff03",
            "282557816b274a2da4bc921dfbc80026",
            "95fb34fa1ae74fb1b59c7d183a529d1f",
            "5dfa654a409442b8b0fdb14a1d298723"
          ]
        },
        "outputId": "2c3f59c0-e7a9-4d48-c3c7-4697532c742b"
      },
      "source": [
        "# load our bert!\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased', # tweet vocab\n",
        "    num_labels = 2, # binary\n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "if exists_gpu():\n",
        "  model.cuda()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0705999e045845be9854e917dd0ab92e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4013e33d385a471382a8670aedc7ce5d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5dfQgVq8C5B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cac049f6-9d0b-44ff-efc3-60a095c446b4"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaZH7fJs4l2W"
      },
      "source": [
        "This is where training is just incase you need to train a current model that has been saved. You also want to load the data from the last run if you want to reproduce it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6InMbo68J50"
      },
      "source": [
        "# this is where our scheduler and optimizer are made :)\n",
        "opt = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "epochs = 3\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(opt, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW_zj7SO8QSK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36520c92-226d-475e-de4f-05ff34745c3a"
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "device = get_gpu()\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        m = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        loss = m[0]\n",
        "        logitcs = m[1]\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        opt.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            m = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            loss = m[0]\n",
        "            logits = m[1]\n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of     76.    Elapsed: 0:00:31.\n",
            "\n",
            "  Average training loss: 0.57\n",
            "  Training epcoh took: 0:00:59\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.54\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of     76.    Elapsed: 0:00:30.\n",
            "\n",
            "  Average training loss: 0.52\n",
            "  Training epcoh took: 0:00:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.55\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of     76.    Elapsed: 0:00:31.\n",
            "\n",
            "  Average training loss: 0.48\n",
            "  Training epcoh took: 0:00:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.69\n",
            "  Validation Loss: 0.58\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:03:01 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQsiusw38Sc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "8ab09137-cfbf-4574-a888-6564daf31fd1"
      },
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "df_stats"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.57</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0:00:59</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.52</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0:00:58</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.48</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0:00:58</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.57         0.54           0.74       0:00:59         0:00:02\n",
              "2               0.52         0.55           0.71       0:00:58         0:00:02\n",
              "3               0.48         0.58           0.69       0:00:58         0:00:02"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvj3Nio-8UQa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "2d847c1a-13aa-47e1-9b6d-09f646ad34e7"
      },
      "source": [
        "sns.set(style='darkgrid')\n",
        "\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "UKWaZqeBptgk",
        "outputId": "105c8b01-c0df-4ebc-fb4e-fcd64e925880"
      },
      "source": [
        "# SAVE THE MODEL FOR LATER USE\n",
        "import pickle\n",
        "\n",
        "save_dir = './model_save/'\n",
        "save_dir_params = './model_save/params/'\n",
        "Create output directory if needed\n",
        "if not os.path.exists(save_dir):\n",
        "  os.makedirs(save_dir)\n",
        "if not os.path.exists(save_dir_params):\n",
        "  os.makedirs(save_dir_params)\n",
        "\n",
        "print('Saving model to %s' % save_dir)\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(save_dir)\n",
        "tokenizer.save_pretrained(save_dir)\n",
        "\n",
        "with open(save_dir_params + 'training_data_loader', 'wb+') as f:\n",
        "  joblib.dump(train_dataloader, f)\n",
        "with open(save_dir_params + 'validation_data_loader', 'wb+') as f:\n",
        "  joblib.dump(validation_dataloader, f)\n",
        "\n",
        "print('Successfuly saved the model to %s' % save_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to /content/drive/bert_model/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-7d9b00f851b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saving model to %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel_to_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'module'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmodel\u001b[0m  \u001b[0;31m# Take care of distributed/parallel training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel_to_save\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36msave_pretrained\u001b[0;34m(self, save_directory)\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Provided path ({}) should be a directory, not a file\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;31m# Only save the model itself if we are using distributed training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 95] Operation not supported: '/content/drive/bert_model/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duYv562Rs24m",
        "outputId": "5c112c55-f284-4260-a138-c80611d50601"
      },
      "source": [
        "!zip -r ./model_save.zip ./model_save"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: model_save/ (stored 0%)\n",
            "  adding: model_save/pytorch_model.bin (deflated 7%)\n",
            "  adding: model_save/tokenizer_config.json (deflated 41%)\n",
            "  adding: model_save/config.json (deflated 45%)\n",
            "  adding: model_save/vocab.txt (deflated 53%)\n",
            "  adding: model_save/params/ (stored 0%)\n",
            "  adding: model_save/params/training_data_loader (deflated 96%)\n",
            "  adding: model_save/params/validation_data_loader (deflated 96%)\n",
            "  adding: model_save/special_tokens_map.json (deflated 40%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "oyu5JmCrtBrC",
        "outputId": "7f199bb6-4cda-469d-ed3b-53eb331a48e9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import files\n",
        "files.download(\"/content/model_save.zip\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_125552d9-a1b6-4106-bffd-71924aad03ed\", \"model_save.zip\", 405867496)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG3rCQlLpRCy"
      },
      "source": [
        "# Tests the data with the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T-7lmO2yoFo"
      },
      "source": [
        "from os import walk\n",
        "tweet_directory = '.'\n",
        "csv_file_test_celeb = 'tweets_test_celeb.csv'\n",
        "f = []\n",
        "for (dirpath, dirnames, filenames) in walk(tweet_directory):\n",
        "    f = filenames\n",
        "    break\n",
        "test_data_celebs = f[int(len(f)//1.2):]\n",
        "\n",
        "device = get_gpu()\n",
        "# Load the dataset into a pandas dataframe.\n",
        "count_test_celebs, sentiments_test_celebs = get_tweets_into_csv_from_celebrities(csv_file=csv_file_test_celeb, files=test_data_celebs)\n",
        "\n",
        "df_test_celeb = pd.read_csv(csv_file_test_celeb, delimiter=',', header=None, \n",
        "                             names=['sentence_source', 'label', \n",
        "                                    'label_notes', 'sentence'])\n",
        "# # Create sentence and label lists\n",
        "sentences = df_test_celeb.sentence.values\n",
        "labels = df_test_celeb.label.values\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 130,\n",
        "                        padding = 'max_length',\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                   )\n",
        "\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# tensors\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, \n",
        "                                   batch_size=batch_size)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETYy83318WDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "947b8943-ab71-4004-c3e1-3922d9a6cb01"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 600 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuuR_J32z4m5",
        "outputId": "c51fb47f-ec7b-4522-aa37-9a86a83ac818"
      },
      "source": [
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)            \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "LUo9_Vvr0EFr",
        "outputId": "5d2f018a-3e02-4d77-dbf4-faa5c2b927dc"
      },
      "source": [
        "# Create a barplot showing the MCC score for each batch of test samples.\n",
        "plt.rcParams[\"figure.figsize\"]=(30, 15)\n",
        "\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2160x1080 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU-hD-N48aB2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75e2274e-eb3d-4ab6-f419-85ec77c2af02"
      },
      "source": [
        "# calculate our score\n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC for BERT: %.3f' % mcc)\n",
        "print('Total MCC for Sentiment: %.3f' % matthews_corrcoef(labels, normalize_sentiment_values(sentiments_test_celebs)))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC for BERT: 0.152\n",
            "600\n",
            "Total MCC for Sentiment: -0.027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdhdxTDFmDnl"
      },
      "source": [
        "## Lingusitic Probability Models\n",
        "We can use lingusitics to study different features of a tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q9qTpkF502_"
      },
      "source": [
        "from emoji import UNICODE_EMOJI\n",
        "\n",
        "def is_emoji(s):\n",
        "    count = 0\n",
        "    for emoji in UNICODE_EMOJI:\n",
        "        count += s.count(emoji)\n",
        "        if count > 1:\n",
        "            return False\n",
        "    return bool(count)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGbVu05i52Z4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be6b9fc9-3762-4888-ecd8-edbb14bb1312"
      },
      "source": [
        "from os import walk\n",
        "tweet_directory = '.'\n",
        "csv_file_celeb = 'tweets_celeb.csv'\n",
        "f = []\n",
        "for (dirpath, dirnames, filenames) in walk(tweet_directory):\n",
        "    f = filenames\n",
        "    break\n",
        "\n",
        "data_celebs = f\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "count_celebs, sentiments_celebs = get_tweets_into_csv_from_celebrities(csv_file=csv_file_celeb, files=data_celebs)\n",
        "\n",
        "df_celeb = pd.read_csv(csv_file_celeb, delimiter=',', header=None, \n",
        "                             names=['sentence_source', 'label', \n",
        "                                    'label_notes', 'sentence'])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File Random_Users.json is corrupted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thNeq5R66FVJ",
        "outputId": "9959fd34-a3e7-438f-f224-7a4b26fda6ea"
      },
      "source": [
        "# lets calculate conditional probabilities of emojis and popularity\n",
        "# and overall proportions\n",
        "\n",
        "labels = list(df_celeb.label.values)\n",
        "sentences = list(df_celeb.sentence.values)\n",
        "\n",
        "emoji_pop = 0\n",
        "emoji_unpop = 0\n",
        "no_emoji_pop = 0\n",
        "no_emoji_unpop = 0\n",
        "\n",
        "for sent, label in zip(sentences, labels):\n",
        "  if is_emoji(sent):\n",
        "    if label == 0:\n",
        "      emoji_unpop += 1\n",
        "    else:\n",
        "      emoji_pop += 1\n",
        "  else:\n",
        "    if label == 0:\n",
        "      no_emoji_unpop += 1\n",
        "    else:\n",
        "      no_emoji_pop += 1\n",
        "\n",
        "total_tweets = len(sentences)\n",
        "p_pop_emoji = (emoji_pop / (total_tweets))/((emoji_pop + emoji_unpop) / (total_tweets))\n",
        "p_unpop_emoji = (emoji_unpop / (total_tweets))/((emoji_pop + emoji_unpop) / (total_tweets))\n",
        "p_pop_no_emoji = (no_emoji_pop / (total_tweets))/((no_emoji_pop + no_emoji_unpop) / (total_tweets))\n",
        "p_unpop_no_emoji = (no_emoji_unpop / (total_tweets))/((no_emoji_pop + no_emoji_unpop) / (total_tweets))\n",
        "\n",
        "print('Popular tweets with emojis: ', emoji_pop)\n",
        "print('P(Popular | Emoji) = ', p_pop_emoji)\n",
        "print('Un-Popular tweets with emojis: ', emoji_unpop)\n",
        "print('P(UnPopular | Emoji) = ', p_unpop_emoji)\n",
        "print('Popular tweets without emojis: ', no_emoji_pop)\n",
        "print('P(Popular | No_Emoji) = ', p_pop_no_emoji)\n",
        "print('Un-Popular tweets without emojis: ', no_emoji_unpop)\n",
        "print('P(UnPopular | No_Emoji) = ', p_unpop_no_emoji)\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Popular tweets with emojis:  107\n",
            "P(Popular | Emoji) =  0.2853333333333333\n",
            "Un-Popular tweets with emojis:  268\n",
            "P(UnPopular | Emoji) =  0.7146666666666667\n",
            "Popular tweets without emojis:  856\n",
            "P(Popular | No_Emoji) =  0.26994638915168717\n",
            "Un-Popular tweets without emojis:  2315\n",
            "P(UnPopular | No_Emoji) =  0.7300536108483128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLCDbYd668YS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da9638d8-de5b-441b-ed55-6947b5ed2995"
      },
      "source": [
        "# HashTags\n",
        "\n",
        "def has_hashtag(sent):\n",
        "  return '#' in sent\n",
        "\n",
        "labels = list(df_celeb.label.values)\n",
        "sentences = list(df_celeb.sentence.values)\n",
        "\n",
        "hashtag_pop = 0\n",
        "hashtag_unpop = 0\n",
        "no_hashtag_pop = 0\n",
        "no_hashtag_unpop = 0\n",
        "\n",
        "for sent, label in zip(sentences, labels):\n",
        "  if has_hashtag(sent):\n",
        "    if label == 0:\n",
        "      hashtag_unpop += 1\n",
        "    else:\n",
        "      hashtag_pop += 1\n",
        "  else:\n",
        "    if label == 0:\n",
        "      no_hashtag_unpop += 1\n",
        "    else:\n",
        "      no_hashtag_pop += 1\n",
        "\n",
        "total_tweets = len(sentences)\n",
        "p_pop_hashtag = (hashtag_pop / (total_tweets))/((hashtag_pop + hashtag_unpop) / (total_tweets))\n",
        "p_unpop_hashtag = (hashtag_unpop / (total_tweets))/((hashtag_pop + hashtag_unpop) / (total_tweets))\n",
        "p_pop_no_hashtag = (no_hashtag_pop / (total_tweets))/((no_hashtag_pop + no_hashtag_unpop) / (total_tweets))\n",
        "p_unpop_no_hashtag = (no_hashtag_unpop / (total_tweets))/((no_hashtag_pop + no_hashtag_unpop) / (total_tweets))\n",
        "\n",
        "print('Popular tweets with hashtags: ', hashtag_pop)\n",
        "print('P(Popular | Hashtag) = ', p_pop_hashtag)\n",
        "print('Un-Popular tweets with hashtags: ', hashtag_unpop)\n",
        "print('P(Un-Popular | Hashtag) = ', p_unpop_hashtag)\n",
        "print('Popular tweets without hastags: ', no_hashtag_pop)\n",
        "print('P(Popular | No Hashtag) = ', p_pop_no_hashtag)\n",
        "print('Un-Popular tweets without hashtags: ', no_hashtag_unpop)\n",
        "print('P(Un-Popular | No Hashtag) = ', p_unpop_no_hashtag)\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Popular tweets with hashtags:  251\n",
            "P(Popular | Hashtag) =  0.21452991452991454\n",
            "Un-Popular tweets with hashtags:  919\n",
            "P(Un-Popular | Hashtag) =  0.7854700854700855\n",
            "Popular tweets without hastags:  712\n",
            "P(Popular | No Hashtag) =  0.29966329966329963\n",
            "Un-Popular tweets without hashtags:  1664\n",
            "P(Un-Popular | No Hashtag) =  0.7003367003367003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xE_5u-DaDjTP",
        "outputId": "aff59423-655c-4b47-c0dd-7e7d5eb76c4a"
      },
      "source": [
        "# Excessive Caps\n",
        "\n",
        "def caps_threshold(sent):\n",
        "  uppers = [l for l in sent if l.isupper()]\n",
        "  letters = [l for l in sent if l.isalpha()]\n",
        "  if len(letters) < 10:\n",
        "    return 0\n",
        "  return len(uppers) / len (letters)\n",
        "\n",
        "labels = list(df_celeb.label.values)\n",
        "sentences = list(df_celeb.sentence.values)\n",
        "\n",
        "caps_pop = 0\n",
        "caps_unpop = 0\n",
        "no_caps_pop = 0\n",
        "no_caps_unpop = 0\n",
        "\n",
        "for sent, label in zip(sentences, labels):\n",
        "  if caps_threshold(sent) >= .20:\n",
        "    if label == 0:\n",
        "      caps_unpop += 1\n",
        "    else:\n",
        "      caps_pop += 1\n",
        "  else:\n",
        "    if label == 0:\n",
        "      no_caps_unpop += 1\n",
        "    else:\n",
        "      no_caps_pop += 1\n",
        "\n",
        "total_tweets = len(sentences)\n",
        "p_pop_caps = (caps_pop / (total_tweets))/((caps_pop + caps_unpop) / (total_tweets))\n",
        "p_unpop_caps = (caps_unpop / (total_tweets))/((caps_pop + caps_unpop) / (total_tweets))\n",
        "p_pop_no_caps = (no_caps_pop / (total_tweets))/((no_caps_pop + no_caps_unpop) / (total_tweets))\n",
        "p_unpop_no_caps = (no_caps_unpop / (total_tweets))/((no_caps_pop + no_caps_unpop) / (total_tweets))\n",
        "\n",
        "print('Popular tweets with caps: ', caps_pop)\n",
        "print('P(Popular | Caps) = ', p_pop_caps)\n",
        "print('Un-Popular tweets with caps: ', caps_unpop)\n",
        "print('P(Un-Popular | Caps) = ', p_unpop_caps)\n",
        "print('Popular tweets without caps: ', no_caps_pop)\n",
        "print('P(Popular | Caps) = ', p_pop_no_caps)\n",
        "print('Un-Popular tweets without caps: ', no_caps_unpop)\n",
        "print('P(Un-Popular | Caps) = ', p_unpop_no_caps)\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Popular tweets with caps:  217\n",
            "P(Popular | Caps) =  0.2866578599735799\n",
            "Un-Popular tweets with caps:  540\n",
            "P(Un-Popular | Caps) =  0.7133421400264202\n",
            "Popular tweets without caps:  746\n",
            "P(Popular | Caps) =  0.26747938329150234\n",
            "Un-Popular tweets without caps:  2043\n",
            "P(Un-Popular | Caps) =  0.7325206167084977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uz_Uy-LRECAI",
        "outputId": "1de50580-674c-4479-b82f-6d58dd6ed060"
      },
      "source": [
        "pop = 0\n",
        "unpop = 0\n",
        "for sent, label in zip(sentences, labels):\n",
        "  if label == 0:\n",
        "    unpop += 1\n",
        "  else:\n",
        "    pop += 1\n",
        "\n",
        "pop_prop = pop/ (pop + unpop)\n",
        "print('Number of Popular Tweets:' , pop)\n",
        "print('Proportion of Popular Tweets:' , pop_prop)\n",
        "print('Number of Un-Popular Tweets:', unpop)\n",
        "print('Proportion of Un-Popular Tweets:', 1-pop_prop)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Popular Tweets: 963\n",
            "Proportion of Popular Tweets: 0.2715736040609137\n",
            "Number of Un-Popular Tweets: 2583\n",
            "Proportion of Un-Popular Tweets: 0.7284263959390863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYRosIyaLlia"
      },
      "source": [
        "# for random users analysis\n",
        "# crashes colab since the data file is too huge\n",
        "\n",
        "from os import walk\n",
        "tweet_directory = '.'\n",
        "data_file_random = 'random_users.json'\n",
        "csv_file_random = 'random_users.csv'\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "count_celebs, sentiments_random = get_tweets_into_csv_from_random(csv_file=csv_file_celeb, file=data_file_random)\n",
        "\n",
        "df_celeb = pd.read_csv(csv_file_celeb, delimiter=',', header=None, \n",
        "                             names=['sentence_source', 'label', \n",
        "                                    'label_notes', 'sentence'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3XoOv1jZ7M8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}